{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances from manager1: [19.903706 22.064589 23.42381 ]\n",
      "Retrieved Document IDs from manager1: ['doc2', 'doc3', 'doc1']\n",
      "Distances from manager2: [18.92828  22.156542 22.338604]\n",
      "Retrieved Document IDs from manager2: ['doc6', 'doc5', 'doc4']\n",
      "Distances from manager1 after loading: [19.903706 22.064589 23.42381 ]\n",
      "Retrieved Document IDs from manager1 after loading: ['doc2', 'doc3', 'doc1']\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "class SingleIndexManager:\n",
    "    def __init__(self, embedding_dim):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.index = faiss.IndexFlatL2(embedding_dim)\n",
    "        self.index_to_doc_id = {}\n",
    "\n",
    "    def add_documents(self, embeddings, doc_ids):\n",
    "        if len(embeddings) != len(doc_ids):\n",
    "            raise ValueError(\"Number of embeddings and document IDs must be the same.\")\n",
    "        \n",
    "        # Add embeddings to FAISS index\n",
    "        self.index.add(embeddings)\n",
    "        \n",
    "        # Map the index positions to document IDs\n",
    "        start_pos = len(self.index_to_doc_id)\n",
    "        for i, doc_id in enumerate(doc_ids):\n",
    "            self.index_to_doc_id[start_pos + i] = doc_id\n",
    "\n",
    "    def search(self, query_embedding, top_k=5):\n",
    "        # Perform the search\n",
    "        distances, indexes = self.index.search(np.array([query_embedding]), top_k)\n",
    "        \n",
    "        # Filter out invalid indices\n",
    "        valid_indices = [i for i in indexes[0] if i >= 0]\n",
    "        \n",
    "        # Retrieve document IDs from the mapping\n",
    "        retrieved_doc_ids = [self.index_to_doc_id[i] for i in valid_indices]\n",
    "        \n",
    "        return distances[0, :len(valid_indices)], retrieved_doc_ids\n",
    "\n",
    "    def save_index(self, index_filepath, mapping_filepath):\n",
    "        faiss.write_index(self.index, index_filepath)\n",
    "        with open(mapping_filepath, \"wb\") as f:\n",
    "            pickle.dump(self.index_to_doc_id, f)\n",
    "\n",
    "    def load_index(self, index_filepath, mapping_filepath):\n",
    "        self.index = faiss.read_index(index_filepath)\n",
    "        with open(mapping_filepath, \"rb\") as f:\n",
    "            self.index_to_doc_id = pickle.load(f)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    embedding_dim = 128\n",
    "    \n",
    "    # Create instances for different indexes\n",
    "    manager1 = SingleIndexManager(embedding_dim)\n",
    "    manager2 = SingleIndexManager(embedding_dim)\n",
    "    manager3 = SingleIndexManager(embedding_dim)\n",
    "    \n",
    "    # Example document embeddings and IDs for manager1\n",
    "    doc_ids_1 = [\"doc1\", \"doc2\", \"doc3\"]\n",
    "    embeddings_1 = np.random.random((len(doc_ids_1), embedding_dim)).astype('float32')\n",
    "    manager1.add_documents(embeddings_1, doc_ids_1)\n",
    "    \n",
    "    # Example document embeddings and IDs for manager2\n",
    "    doc_ids_2 = [\"doc4\", \"doc5\", \"doc6\"]\n",
    "    embeddings_2 = np.random.random((len(doc_ids_2), embedding_dim)).astype('float32')\n",
    "    manager2.add_documents(embeddings_2, doc_ids_2)\n",
    "    \n",
    "    # Perform a search on manager1\n",
    "    query_embedding_1 = np.random.random((embedding_dim,)).astype('float32')\n",
    "    distances_1, retrieved_doc_ids_1 = manager1.search(query_embedding_1)\n",
    "\n",
    "    print(\"Distances from manager1:\", distances_1)\n",
    "    print(\"Retrieved Document IDs from manager1:\", retrieved_doc_ids_1)\n",
    "    \n",
    "    # Perform a search on manager2\n",
    "    query_embedding_2 = np.random.random((embedding_dim,)).astype('float32')\n",
    "    distances_2, retrieved_doc_ids_2 = manager2.search(query_embedding_2)\n",
    "\n",
    "    print(\"Distances from manager2:\", distances_2)\n",
    "    print(\"Retrieved Document IDs from manager2:\", retrieved_doc_ids_2)\n",
    "    \n",
    "    # Save indexes to disk\n",
    "    manager1.save_index(\"index1.index\", \"mapping1.pkl\")\n",
    "    manager2.save_index(\"index2.index\", \"mapping2.pkl\")\n",
    "    manager3.save_index(\"index3.index\", \"mapping3.pkl\")\n",
    "    \n",
    "    # Load indexes from disk\n",
    "    manager1.load_index(\"index1.index\", \"mapping1.pkl\")\n",
    "    manager2.load_index(\"index2.index\", \"mapping2.pkl\")\n",
    "    manager3.load_index(\"index3.index\", \"mapping3.pkl\")\n",
    "    \n",
    "    # Perform the search again to verify\n",
    "    distances_1, retrieved_doc_ids_1 = manager1.search(query_embedding_1)\n",
    "    print(\"Distances from manager1 after loading:\", distances_1)\n",
    "    print(\"Retrieved Document IDs from manager1 after loading:\", retrieved_doc_ids_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
