{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances from manager1: [(18.08528, 'doc2'), (19.313034, 'doc3'), (19.591436, 'doc1')]\n",
      "Distances from manager2: [(18.968998, 'doc6'), (21.379908, 'doc4'), (22.222712, 'doc5')]\n",
      "Distances from manager1 after loading: [(18.08528, 'doc2'), (19.313034, 'doc3'), (19.591436, 'doc1')]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "class SingleIndexManager:\n",
    "    def __init__(self, embedding_dim):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.index = faiss.IndexFlatL2(embedding_dim)\n",
    "        self.index_to_doc_id = {}\n",
    "\n",
    "    def add_documents(self, embeddings, doc_ids):\n",
    "        if len(embeddings) != len(doc_ids):\n",
    "            raise ValueError(\"Number of embeddings and document IDs must be the same.\")\n",
    "        \n",
    "        # Add embeddings to FAISS index\n",
    "        self.index.add(embeddings)\n",
    "        \n",
    "        # Map the index positions to document IDs\n",
    "        start_pos = len(self.index_to_doc_id)\n",
    "        for i, doc_id in enumerate(doc_ids):\n",
    "            self.index_to_doc_id[start_pos + i] = doc_id\n",
    "\n",
    "    def search(self, query_embedding, top_k=10):\n",
    "        # Perform the search\n",
    "        distances, indexes = self.index.search(np.array([query_embedding]), top_k)\n",
    "        \n",
    "        # Filter out invalid indices\n",
    "        valid_indices = [i for i in indexes[0] if i >= 0]\n",
    "        \n",
    "        # Retrieve document IDs from the mapping\n",
    "        retrieved_doc_ids = [self.index_to_doc_id[i] for i in valid_indices]\n",
    "\n",
    "        # zip the distances and retrieved_doc_ids\n",
    "        return list(zip(distances[0, :len(valid_indices)], retrieved_doc_ids))\n",
    "        \n",
    "    def save_index(self, index_filepath, mapping_filepath):\n",
    "        faiss.write_index(self.index, index_filepath)\n",
    "        with open(mapping_filepath, \"wb\") as f:\n",
    "            pickle.dump(self.index_to_doc_id, f)\n",
    "\n",
    "    def load_index(self, index_filepath, mapping_filepath):\n",
    "        self.index = faiss.read_index(index_filepath)\n",
    "        with open(mapping_filepath, \"rb\") as f:\n",
    "            self.index_to_doc_id = pickle.load(f)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    embedding_dim = 128\n",
    "    \n",
    "    # Create instances for different indexes\n",
    "    manager1 = SingleIndexManager(embedding_dim)\n",
    "    manager2 = SingleIndexManager(embedding_dim)\n",
    "    manager3 = SingleIndexManager(embedding_dim)\n",
    "    \n",
    "    # Example document embeddings and IDs for manager1\n",
    "    doc_ids_1 = [\"doc1\", \"doc2\", \"doc3\"]\n",
    "    embeddings_1 = np.random.random((len(doc_ids_1), embedding_dim)).astype('float32')\n",
    "    manager1.add_documents(embeddings_1, doc_ids_1)\n",
    "    \n",
    "    # Example document embeddings and IDs for manager2\n",
    "    doc_ids_2 = [\"doc4\", \"doc5\", \"doc6\"]\n",
    "    embeddings_2 = np.random.random((len(doc_ids_2), embedding_dim)).astype('float32')\n",
    "    manager2.add_documents(embeddings_2, doc_ids_2)\n",
    "    \n",
    "    # Perform a search on manager1\n",
    "    query_embedding_1 = np.random.random((embedding_dim,)).astype('float32')\n",
    "    results = manager1.search(query_embedding_1)\n",
    "\n",
    "    print(\"Distances from manager1:\", results)\n",
    "    \n",
    "    # Perform a search on manager2\n",
    "    query_embedding_2 = np.random.random((embedding_dim,)).astype('float32')\n",
    "    results = manager2.search(query_embedding_2)\n",
    "\n",
    "    print(\"Distances from manager2:\", results)\n",
    "\n",
    "    \n",
    "    # Save indexes to disk\n",
    "    manager1.save_index(\"index1.index\", \"mapping1.pkl\")\n",
    "    manager2.save_index(\"index2.index\", \"mapping2.pkl\")\n",
    "    manager3.save_index(\"index3.index\", \"mapping3.pkl\")\n",
    "    \n",
    "    # Load indexes from disk\n",
    "    manager1.load_index(\"index1.index\", \"mapping1.pkl\")\n",
    "    manager2.load_index(\"index2.index\", \"mapping2.pkl\")\n",
    "    manager3.load_index(\"index3.index\", \"mapping3.pkl\")\n",
    "    \n",
    "    # Perform the search again to verify\n",
    "    results = manager1.search(query_embedding_1)\n",
    "    print(\"Distances from manager1 after loading:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mishael/Desktop/SLMs-based-RAG/datasets/scifact.zip: 100%|██████████| 2.69M/2.69M [00:00<00:00, 7.63MiB/s]\n",
      "100%|██████████| 5183/5183 [00:00<00:00, 148479.81it/s]\n"
     ]
    }
   ],
   "source": [
    "from beir import util\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "\n",
    "#### Download scifact.zip dataset and unzip the dataset\n",
    "dataset = \"scifact\"\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset)\n",
    "out_dir = '/Users/mishael/Desktop/SLMs-based-RAG/datasets'\n",
    "data_path = util.download_and_unzip(url, out_dir)\n",
    "\n",
    "#### Provide the data_path where scifact has been downloaded and unzipped\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "models_name = \"Snowflake/snowflake-arctic-embed-m\"\n",
    "\n",
    "model = SentenceTransformer(models_name)    \n",
    "\n",
    "model_manager = SingleIndexManager(model.get_sentence_embedding_dimension())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# index all the documents\n",
    "docs_embeddings = model.encode([doc['title'] + ' ' + doc['text'] for doc in corpus.values()])\n",
    "docs_ids = list(corpus.keys())\n",
    "model_manager.add_documents(docs_embeddings, docs_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.70065176, '29495185'),\n",
       " (0.7251548, '22635278'),\n",
       " (0.78605103, '23531592'),\n",
       " (0.80004704, '13042119'),\n",
       " (0.85905784, '2762601')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a search on the indexed documents\n",
    "query = \"What is the incubation period of COVID-19?\"\n",
    "query_embedding = model.encode(query)\n",
    "results = model_manager.search(query_embedding)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ap': 1.1787301587301586, 'p3': 0.6666666666666666, 'p5': 0.6, 'recall': 1.0}\n"
     ]
    }
   ],
   "source": [
    "def calculate_ir_metrics(result_ids, relevant_ids):\n",
    "    relevant_set = set(relevant_ids)\n",
    "    num_relevant = len(relevant_set)\n",
    "    \n",
    "    if num_relevant == 0:\n",
    "        return {\"ap\": 0.0, \"p3\": 0.0, \"p5\": 0.0, \"recall\": 0.0}\n",
    "    \n",
    "    hits = 0\n",
    "    sum_precisions = 0.0\n",
    "    p3, p5 = 0.0, 0.0\n",
    "    \n",
    "    for i, result in enumerate(result_ids, 1):\n",
    "        if result in relevant_set:\n",
    "            hits += 1\n",
    "        precision = hits / i\n",
    "        sum_precisions += precision\n",
    "            \n",
    "        if i == 3:\n",
    "            p3 = precision\n",
    "        elif i == 5:\n",
    "            p5 = precision\n",
    "    \n",
    "    ap = sum_precisions / num_relevant\n",
    "    recall = hits / num_relevant\n",
    "    \n",
    "    return {\n",
    "        \"ap\": ap,\n",
    "        \"p3\": p3,\n",
    "        \"p5\": p5,\n",
    "        \"recall\": recall\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "result_ids = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "relevant_ids = [1, 3, 5, 7, 9]\n",
    "metrics = calculate_ir_metrics(result_ids, relevant_ids)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ap</th>\n",
       "      <th>p3</th>\n",
       "      <th>p5</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.195833</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ap        p3   p5  recall\n",
       "0    0.000000  0.000000  0.0    0.00\n",
       "1    0.000000  0.000000  0.0    0.00\n",
       "2    0.000000  0.000000  0.0    0.00\n",
       "3    0.000000  0.000000  0.0    0.00\n",
       "4    0.000000  0.000000  0.0    0.00\n",
       "..        ...       ...  ...     ...\n",
       "295  0.195833  0.333333  0.2    0.25\n",
       "296  0.000000  0.000000  0.0    0.00\n",
       "297  0.000000  0.000000  0.0    0.00\n",
       "298  0.000000  0.000000  0.0    0.00\n",
       "299  0.000000  0.000000  0.0    0.00\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Calculate IR metrics for all queries\n",
    "ir_metrics = []\n",
    "\n",
    "\n",
    "for query_id, query in queries.items():\n",
    "    query_embedding = model.encode(query)\n",
    "    results = model_manager.search(query_embedding)\n",
    "    result_ids = [doc_id for _, doc_id in results]\n",
    "    relevant_ids = [doc_id for doc_id in qrels[query_id]]\n",
    "    \n",
    "    metrics = calculate_ir_metrics(result_ids, relevant_ids)\n",
    "    ir_metrics.append(metrics)\n",
    "\n",
    "metric_df = pd.DataFrame(ir_metrics)\n",
    "\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ap        0.182597\n",
       "p3        0.035556\n",
       "p5        0.036000\n",
       "recall    0.167500\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the average metrics\n",
    "\n",
    "avg_metrics = metric_df.mean()\n",
    "\n",
    "avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused and ranked result:\n",
      "Document ID: 1, Fused Score: 2.8297\n",
      "Document ID: 2, Fused Score: 2.7310\n",
      "Document ID: 3, Fused Score: 2.7190\n",
      "Document ID: 4, Fused Score: 1.5614\n",
      "Document ID: 5, Fused Score: 0.8235\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import defaultdict\n",
    "\n",
    "def combsum_fusion(ranked_lists):\n",
    "    \"\"\"\n",
    "    Perform CombSum fusion on multiple ranked lists with efficient score normalization.\n",
    "    \n",
    "    :param ranked_lists: A list of lists, where each inner list contains tuples of (doc_id, score)\n",
    "    :return: A list of tuples (doc_id, fused_score) sorted by fused_score in descending order\n",
    "    \"\"\"\n",
    "    # Create a set of all unique document IDs\n",
    "    all_doc_ids = set(doc_id for ranked_list in ranked_lists for doc_id, _ in ranked_list)\n",
    "    \n",
    "    # Create a dictionary to map document IDs to their index in the numpy array\n",
    "    doc_id_to_index = {doc_id: i for i, doc_id in enumerate(all_doc_ids)}\n",
    "    \n",
    "    # Initialize a numpy array to hold all scores\n",
    "    scores_array = np.zeros((len(all_doc_ids), len(ranked_lists)))\n",
    "    \n",
    "    # Fill the scores array\n",
    "    for list_idx, ranked_list in enumerate(ranked_lists):\n",
    "        for doc_id, score in ranked_list:\n",
    "            scores_array[doc_id_to_index[doc_id], list_idx] = score\n",
    "    \n",
    "    # Normalize scores using MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_scores = scaler.fit_transform(scores_array)\n",
    "    \n",
    "    # Sum up the normalized scores\n",
    "    fused_scores = np.sum(normalized_scores, axis=1)\n",
    "    \n",
    "    # Create the fused list of (doc_id, score) tuples\n",
    "    fused_list = [(doc_id, fused_scores[idx]) for doc_id, idx in doc_id_to_index.items()]\n",
    "    \n",
    "    # Sort the fused list by score in descending order\n",
    "    fused_list.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return fused_list\n",
    "\n",
    "# Example usage\n",
    "list1 = [(1, 90), (2, 80), (3, 70), (4, 60)]\n",
    "list2 = [(2, 0.85), (3, 0.8), (1, 0.75), (5, 0.7)]\n",
    "list3 = [(3, 950), (1, 900), (4, 850), (2, 800)]\n",
    "\n",
    "ranked_lists = [list1, list2, list3]\n",
    "fused_result = combsum_fusion(ranked_lists)\n",
    "print(\"Fused and ranked result:\")\n",
    "for doc_id, score in fused_result:\n",
    "    print(f\"Document ID: {doc_id}, Fused Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused and ranked result using RRF:\n",
      "Document ID: 1, Fused Score: 0.0484\n",
      "Document ID: 3, Fused Score: 0.0484\n",
      "Document ID: 2, Fused Score: 0.0481\n",
      "Document ID: 4, Fused Score: 0.0315\n",
      "Document ID: 5, Fused Score: 0.0156\n"
     ]
    }
   ],
   "source": [
    "def rrf_fusion(ranked_lists, k=60):\n",
    "    \"\"\"\n",
    "    Perform Reciprocal Rank Fusion on multiple ranked lists.\n",
    "    \n",
    "    :param ranked_lists: A list of lists, where each inner list contains tuples of (doc_id, score)\n",
    "    :param k: The constant in the RRF formula (default is 60 as per the original paper)\n",
    "    :return: A list of tuples (doc_id, fused_score) sorted by fused_score in descending order\n",
    "    \"\"\"\n",
    "    fused_scores = defaultdict(float)\n",
    "    \n",
    "    for ranked_list in ranked_lists:\n",
    "        for rank, (doc_id, _) in enumerate(ranked_list, start=1):\n",
    "            fused_scores[doc_id] += 1 / (k + rank)\n",
    "    \n",
    "    # Sort the fused list by score in descending order\n",
    "    fused_list = sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return fused_list\n",
    "\n",
    "# Example usage\n",
    "list1 = [(1, 0.9), (2, 0.8), (3, 0.7), (4, 0.6)]\n",
    "list2 = [(2, 0.85), (3, 0.8), (1, 0.75), (5, 0.7)]\n",
    "list3 = [(3, 0.95), (1, 0.9), (4, 0.85), (2, 0.8)]\n",
    "\n",
    "ranked_lists = [list1, list2, list3]\n",
    "fused_result = rrf_fusion(ranked_lists)\n",
    "print(\"Fused and ranked result using RRF:\")\n",
    "for doc_id, score in fused_result:\n",
    "    print(f\"Document ID: {doc_id}, Fused Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_queries_results(queries, model_manager, output_path):\n",
    "    result_dict = {}\n",
    "    for query_id, query in queries.items():\n",
    "        query_embedding = model.encode(query)\n",
    "        results = model_manager.search(query_embedding)\n",
    "        result_dict[query_id] = results\n",
    "    save_json(result_dict, output_path)\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_json(data, output_path):\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "def load_json(input_path):\n",
    "    with open(input_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMBSUM_RESULTS_PATH = \"combsum_results.json\"\n",
    "RRF_RESULTS_PATH = \"rrf_results.json\"\n",
    "\n",
    "def comb_results(queries_result_folder, output_path):\n",
    "    comb_results = {}\n",
    "    rrf_result = {}\n",
    "    queries_results = {json_path.stem: load_json(json_path) for json_path in queries_result_folder.iterdir()}\n",
    "\n",
    "    first_signal = list(queries_results.keys())[0]\n",
    "    for query_id in queries_results[first_signal]:\n",
    "        ranked_lists = [queries_results[signal][query_id] for signal in queries_results]\n",
    "        comb_results[query_id] = combsum_fusion(ranked_lists)\n",
    "        rrf_result[query_id] = rrf_fusion(ranked_lists)\n",
    "\n",
    "    save_json(comb_results, output_path / COMBSUM_RESULTS_PATH)\n",
    "    save_json(rrf_result, output_path / RRF_RESULTS_PATH)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {1: [(1, 0.9), (2, 0.8), (3, 0.7), (4, 0.6)], 2: [(2, 0.85), (3, 0.8), (1, 0.75), (5, 0.7)]}\n",
    "\n",
    "list(a.keys())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
